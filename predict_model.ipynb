{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part II: Predictive Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anqi\\Anaconda3\\lib\\site-packages\\sklearn\\cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer, TfidfTransformer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.cluster import MiniBatchKMeans\n",
    "from sklearn.linear_model import SGDRegressor\n",
    "from sklearn.pipeline import Pipeline, FeatureUnion\n",
    "from sklearn.cross_validation import KFold\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.base import TransformerMixin\n",
    "from sklearn.metrics import log_loss\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from bs4 import BeautifulSoup \n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "import random\n",
    "import re\n",
    "from collections import defaultdict\n",
    "from transformers import *\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# variables\n",
    "random_state = 2017"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# predictor\n",
    "predictor_gb = GradientBoostingClassifier(subsample=0.5, random_state=random_state, max_features='sqrt')\n",
    "gb_params = dict(Predictor__learning_rate=[0.01, 0.1, 0.5],\n",
    "                 Predictor__n_estimators=[30, 50, 100, 500],\n",
    "                 Predictor__max_depth=[3, 5, 10]\n",
    ")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Predictor__learning_rate': [0.01, 0.1, 0.5],\n",
       " 'Predictor__max_depth': [3, 5, 10],\n",
       " 'Predictor__n_estimators': [30, 50, 100, 500]}"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gb_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predictor_rf = RandomForestClassifier(n_estimators=10, criterion='gini', max_depth=None, min_samples_split=2, \n",
    "                                      min_samples_leaf=1, min_weight_fraction_leaf=0.0, max_features='auto', \n",
    "                                      max_leaf_nodes=None, min_impurity_split=1e-07, bootstrap=True, oob_score=False, n_jobs=1, \n",
    "                                      random_state=None, verbose=0, warm_start=False, class_weight=None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predictor_ada = AdaBoostClassifier(base_estimator=None, n_estimators=50, learning_rate=1.0, algorithm='SAMME.R', \n",
    "                                   random_state=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# make a cv generator\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=random_state)\n",
    "\n",
    "# make a scorer\n",
    "scorer_log_loss = make_scorer(log_loss, greater_is_better=False, needs_proba=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class RentalPredict():\n",
    "    def __init__(self, featureunion, predictor, param_dict, cv, scorer):\n",
    "        self.estimator = Pipeline([\n",
    "                ('Feature_Unions', featureunion),\n",
    "                ('Predictor', predictor)\n",
    "            ])\n",
    "        self.param_grid = param_dict\n",
    "        self.cv = cv\n",
    "        self.scorer = scorer\n",
    "        self.Grid_model = GridSearchCV(estimator=self.estimator, param_grid=self.param_grid, cv=self.cv, scoring='neg_log_loss')\n",
    "\n",
    "        \n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        # Grid Search\n",
    "        self.Grid_model.fit(X, y)\n",
    "        return self\n",
    "    \n",
    "    def get_gridmodel(self):\n",
    "        return self.Grid_model\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_predprob(grid_model, test_X, tocsv=False, filename=None):\n",
    "    test_pred_prob = grid_model.predict_proba(test_X)\n",
    "    test_pred_prob_set = pd.DataFrame(test_pred_prob, columns=grid_model.best_estimator_.classes_, index=test_set.index)\n",
    "    test_pred_prob_set = test_pred_prob_set.join(test_set['listing_id'])\n",
    "    col_orders = ['listing_id', 'high', 'medium', 'low']\n",
    "    test_pred_prob_set = test_pred_prob_set[col_orders]\n",
    "    if tocsv:\n",
    "        test_pred_prob_set.to_csv(filename, index = False)\n",
    "    return test_pred_prob_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Feature Unions\n",
    "# build pipelines\n",
    "variable_unchanged = Pipeline([('variable_extractor', VariableExtractor(['bedrooms', 'bathrooms', 'price']))])\n",
    "bbratio = Pipeline([\n",
    "        ('room_ratio', RatioCreator('bedrooms', 'bathrooms')),\n",
    "        ('bbratio_dimup', DimOneUp())\n",
    "    ])\n",
    "bpratio = Pipeline([\n",
    "        ('priceroom_ratio', RatioCreator('price', 'bedrooms')),\n",
    "        ('bpratio_dimup', DimOneUp())\n",
    "    ])\n",
    "llcluster = Pipeline([\n",
    "        ('ll_extractor', VariableExtractor(['longitude', 'latitude'])),\n",
    "        ('ll_cluster', LLCluster(init='k-means++', n_clusters=10, batch_size=200, n_init=10, \n",
    "                                 max_no_improvement=10, verbose=0, random_state=random_state)),\n",
    "        ('llcluster_dimup', DimOneUp())                     \n",
    "    ])\n",
    "\n",
    "feature_process = Pipeline([\n",
    "        ('feature_cleanser', FeatureCleanser()),\n",
    "        ('feature_union', FeatureUnion([\n",
    "                    ('feature_counts', Pipeline([\n",
    "                                ('feature_length', VariableLength()),\n",
    "                                ('feature_dimup', DimOneUp())\n",
    "                            ])),\n",
    "                    ('different_features', DiffFeatCounts())\n",
    "                ]))\n",
    "    ])\n",
    "\n",
    "description_process = FeatureUnion([\n",
    "        ('description_length', Pipeline([('description_counts', DescriptionWordCounts()),\n",
    "                                     ('dc_dimup', DimOneUp())\n",
    "                                    ])\n",
    "        ), \n",
    "        ('description_tf', DescriptionProcessor())\n",
    "    ])\n",
    "\n",
    "photo_length = Pipeline([('photo_extractor', VariableExtractor('photos')),\n",
    "                         ('photo_counts', VariableLength()), \n",
    "                         ('photo_dimup', DimOneUp())\n",
    "    ])\n",
    "\n",
    "building_process = Pipeline([\n",
    "        ('building_extractor', VariableExtractor('building_id')),\n",
    "        ('building_union', FeatureUnion([\n",
    "                    ('building_counts', Pipeline([\n",
    "                                ('building_length', CatVariableCounts()),\n",
    "                                ('building_dimup', DimOneUp())\n",
    "                            ])),\n",
    "                    ('building_indicator', CatVariableIndicator())\n",
    "                ]))\n",
    "    ])\n",
    "\n",
    "manager_process = Pipeline([\n",
    "        ('manager_extractor', VariableExtractor('manager_id')),\n",
    "        ('manager_union', FeatureUnion([\n",
    "                    ('manager_counts', Pipeline([\n",
    "                                ('manager_length', CatVariableCounts()),\n",
    "                                ('manager_dimup', DimOneUp())\n",
    "                            ])),\n",
    "                    ('manager_indicator', CatVariableIndicator())\n",
    "                ]))\n",
    "    ])\n",
    "\n",
    "date_process = Pipeline([\n",
    "        ('hour_extractor', DateProcessor(wantyear=False, wantmonth=False, wanthour=True)),\n",
    "        ('hour_dimup', DimOneUp())\n",
    "    ])\n",
    "\n",
    "address_process = Pipeline([\n",
    "        ('address_cleanser', AddressCleanser()),\n",
    "        ('address_union', FeatureUnion([\n",
    "                    ('address_counts', Pipeline([\n",
    "                                ('address_length', CatVariableCounts()),\n",
    "                                ('address_dimup', DimOneUp())\n",
    "                            ])),\n",
    "                    ('address_indicator', CatVariableIndicator())\n",
    "                ]))\n",
    "    ])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Read in training data set with size of 49352 * 15\n",
      "Read in testing data set with size of 74659 * 14\n"
     ]
    }
   ],
   "source": [
    "# read in the data \n",
    "# read in the training data set\n",
    "train_set = pd.read_json(r'..\\data\\train.json')\n",
    "test_set = pd.read_json(r'..\\data\\test.json')\n",
    "print(\"Read in training data set with size of {} * {}\".format(train_set.shape[0], train_set.shape[1]))\n",
    "print(\"Read in testing data set with size of {} * {}\".format(test_set.shape[0], test_set.shape[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "N = 3000\n",
    "train_X = train_set.iloc[:3000].drop('interest_level', axis=1)\n",
    "train_y = train_set.iloc[:3000]['interest_level']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "rp_try = RentalPredict(variable_unchanged, predictor_gb, gb_params, cv, scorer_log_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<__main__.RentalPredict at 0x1a958f09f60>"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rp_try.fit(train_X, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model_try = rp_try.get_gridmodel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.72633535736205157"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_try.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Predictor__learning_rate': 0.01,\n",
       " 'Predictor__max_depth': 3,\n",
       " 'Predictor__n_estimators': 500}"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_try.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pred_try = model_try.predict_proba(test_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.04878566,  0.74566373,  0.20555062],\n",
       "       [ 0.09721395,  0.5741655 ,  0.32862055],\n",
       "       [ 0.03090766,  0.86356531,  0.10552703],\n",
       "       [ 0.0651726 ,  0.63616919,  0.29865821],\n",
       "       [ 0.04143167,  0.82109574,  0.13747259],\n",
       "       [ 0.01154865,  0.95722645,  0.0312249 ],\n",
       "       [ 0.09799949,  0.56887869,  0.33312181],\n",
       "       [ 0.10022034,  0.57378729,  0.32599237],\n",
       "       [ 0.08216564,  0.56358297,  0.35425139],\n",
       "       [ 0.07926138,  0.61857601,  0.30216261]])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_try[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pred_try = create_predprob(model_try, test_set, tocsv=True, filename=r'..\\data\\predictions\\gb_try_3var.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>listing_id</th>\n",
       "      <th>high</th>\n",
       "      <th>medium</th>\n",
       "      <th>low</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7142618</td>\n",
       "      <td>0.048786</td>\n",
       "      <td>0.205551</td>\n",
       "      <td>0.745664</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7210040</td>\n",
       "      <td>0.097214</td>\n",
       "      <td>0.328621</td>\n",
       "      <td>0.574165</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>7103890</td>\n",
       "      <td>0.030908</td>\n",
       "      <td>0.105527</td>\n",
       "      <td>0.863565</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1000</th>\n",
       "      <td>7143442</td>\n",
       "      <td>0.065173</td>\n",
       "      <td>0.298658</td>\n",
       "      <td>0.636169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100000</th>\n",
       "      <td>6860601</td>\n",
       "      <td>0.041432</td>\n",
       "      <td>0.137473</td>\n",
       "      <td>0.821096</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        listing_id      high    medium       low\n",
       "0          7142618  0.048786  0.205551  0.745664\n",
       "1          7210040  0.097214  0.328621  0.574165\n",
       "100        7103890  0.030908  0.105527  0.863565\n",
       "1000       7143442  0.065173  0.298658  0.636169\n",
       "100000     6860601  0.041432  0.137473  0.821096"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "a = GradientBoostingClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GradientBoostingClassifier(criterion='friedman_mse', init=None,\n",
       "              learning_rate=0.1, loss='deviance', max_depth=3,\n",
       "              max_features=None, max_leaf_nodes=None,\n",
       "              min_impurity_split=1e-07, min_samples_leaf=1,\n",
       "              min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "              n_estimators=100, presort='auto', random_state=None,\n",
       "              subsample=1.0, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.fit(train_X[['bedrooms', 'price']], train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['high', 'low', 'medium'], dtype=object)"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.classes_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
